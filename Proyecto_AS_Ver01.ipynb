{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPcmLFgO2ZtLFT4Or93gjh7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GBig-UTP2023/GBig-UTP2023/blob/main/Proyecto_AS_Ver01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download es_core_news_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xz-4UuDxuCRb",
        "outputId": "49745455-492d-4e89-ce5c-c7c189b390bf"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-10-26 23:15:59.744318: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-10-26 23:15:59.744393: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-10-26 23:15:59.744428: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-10-26 23:16:01.080083: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting es-core-news-sm==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.6.0/es_core_news_sm-3.6.0-py3-none-any.whl (12.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from es-core-news-sm==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (0.1.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (2.1.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###Conjunto de datos de entrenamiento y factorización de los datos\n",
        "\n",
        "training_data=[\n",
        "              (\"Me encanta el contenido del blog de Analytics Lane, los artículos son fantásticos.\", \"positivo\"),\n",
        "              (\"El código no funciona, me ha dado un error al ejecutarlos.\", \"negativo\"),\n",
        "              (\"Me encanta este producto.\",\"positivo\"),\n",
        "              (\"Esta película fue terrible.\",\"negativo\"),\n",
        "              (\"El clima está agradable hoy.\",\"positivo\"),\n",
        "              (\"Me siento triste por las noticias.\",\"negativo\"),\n",
        "              (\"Es solo un libro promedio\",\"neutral\")\n",
        "              ]"
      ],
      "metadata": {
        "id": "SahvvJSY8KGW"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Creando función para analizar conjunto de datos\n",
        "\n",
        "import spacy\n",
        "\n",
        "def preprocess_text(text):\n",
        "  \"\"\"\n",
        "  Realiza el preprocesamiento básico de un texto en idioma español utilizando spacy.\n",
        "\n",
        "  Args:\n",
        "      txtFrase(str): El texto al ser preprocesado.\n",
        "\n",
        "  Returns:\n",
        "      str: El texto preprocesado\n",
        " \"\"\"\n",
        "  nlp = spacy.load('es_core_news_sm')\n",
        "  doc = nlp(text)\n",
        "\n",
        "  # Eliminación de palabra irrelevantes (stopwords) y signos de puntuación\n",
        "\n",
        "  tokens = [token.lemma_.lower() for token in doc if not token.is_stop and not token.is_punct]\n",
        "\n",
        "  # Recontrucción del text preprocesado\n",
        "  preprocessed_text=' '.join(tokens)\n",
        "\n",
        "  return preprocessed_text\n",
        "\n"
      ],
      "metadata": {
        "id": "665Ygg_W_ZWn"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Creando función para crear caracteristicas del texto a analizar.\n",
        "\n",
        "def extract_features(text):\n",
        "    \"\"\"\n",
        "    Extrae las características del texto utilizando spaCy y devuelve un dicciorario de características.\n",
        "\n",
        "    Arg:\n",
        "    txtFrase (str): El texto de cual extraer características.\n",
        "    Returns:\n",
        "    dict: Un diccionario que representa las características extraídas del texto.\n",
        "    \"\"\"\n",
        "    features={}\n",
        "    doc = nlp (text)\n",
        "    for token in doc:\n",
        "      if not token.is_stop and not token.is_punct:\n",
        "        if token.lemma_.lower() in features:\n",
        "          features[token.lemma_.lower()] += 1\n",
        "        else:\n",
        "          features[token.lemma_.lower()] = 1\n",
        "    return features\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "--AgJNSPBZmf"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Entrenamiento del modelo ::::En AS el modelo que mejor funciona es Naive Bayes spacy no cuenta con una implementación propia,\n",
        "#                             pero es posible usar Scikit-learn que consta de preprocesar los datos, extraer las caracteristicas y crear un conjunto de entrenamiento\n",
        "#                             para el modelo MultinominalNB()\n",
        "\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "#Preprocesamiento de los datos de entrenamiento\n",
        "\n",
        "preprocessed_training_data=[(preprocess_text(text), label) for text, label in training_data]\n",
        "\n",
        "#Extracción de características de los datos de entrenamiento\n",
        "\n",
        "training_features = [extract_features(text) for text, _ in\n",
        "                     preprocessed_training_data]\n",
        "vectorizer = DictVectorizer(sparse=False)\n",
        "X_train = vectorizer.fit_transform(training_features)\n",
        "\n",
        "#Etiquetas de los datos de entrenamiento\n",
        "\n",
        "y_train = [label for _, label in preprocessed_training_data]\n",
        "\n",
        "#Entrenamiento del clasificador Naive Bayer\n",
        "\n",
        "classifier = MultinomialNB()\n",
        "_ = classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "HSPlRmCTyP6w"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Nuevo texto para clasificar\n",
        "new_text=\"Es un carro expetacular\"\n",
        "\n",
        "#Preprocesamiento del nuevo texto\n",
        "preprocessed_text = preprocess_text(new_text)\n",
        "\n",
        "#Extracción de características del nuevo texto\n",
        "\n",
        "features=extract_features(preprocessed_text)\n",
        "X_test=vectorizer.transform([features])\n",
        "\n",
        "#Clasificación del nuevo texto\n",
        "sentiment = classifier.predict(X_test)\n",
        "print(\"Sentimiento: \", sentiment[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9RzD3byJNAr",
        "outputId": "dd71ee8f-a93a-44ee-dd42-9c7869372a94"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentimiento:  negativo\n"
          ]
        }
      ]
    }
  ]
}